{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdb5SS7msZU_"
   },
   "source": [
    "# What is Dingocar\n",
    "\n",
    "ToDo\n",
    "\n",
    "# TDX Dingocar Exploration\n",
    "\n",
    "The aim of this notebook is to implement the Dingocar self-driving roboar CNN using TFX components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3n2dQoLlukM1",
    "outputId": "9acc2e77-87f6-46ab-d73c-02118dce23e5"
   },
   "outputs": [],
   "source": [
    "!pip install \"tfx==0.21.2\" \"tensorflow>=2.1,<2.2\" \"tensorboard>=2.1,<2.3\" \"pyzmq==17.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spqarW5rva70"
   },
   "source": [
    "**Not sure how many of these we need, will remove undeeded later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Tfb_cvQysUu1",
    "outputId": "c0ba1975-ab58-4513-dec2-8af0ac1bd681"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "import absl\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "tf.get_logger().propagate = False\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "import tfx\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import ResolverNode\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.proto.evaluator_pb2 import SingleSlicingSpec\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.types.standard_artifacts import ModelBlessing\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-YZXM5ZXvnGm",
    "outputId": "2bd3a0fc-9cdc-4f3a-ce31-9a4954c47317"
   },
   "outputs": [],
   "source": [
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-c75XYPvU7N8"
   },
   "source": [
    "# Download data from public google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "2RsbFxAFU6tH",
    "outputId": "f84154bd-0764-4668-8f66-0f326b7af69f"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install gdown\n",
    "mkdir data\n",
    "gdown --id 1gv5k5vK90QOSgenwT42DMm-jmBdB9yEX --output data/tub.zip\n",
    "(cd data && unzip tub.zip > _ && cd ..)\n",
    "echo \"Number of examples: `ls data/tub/*.jpg | wc -l`\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10KRW13TsOQb"
   },
   "source": [
    "## Connect to Google Drive\n",
    "\n",
    "This piece of code will mount the your google drive to this Google Colab virtual machine. It will prompt you to follow a link to get a verification code. Once you get it, copy and paste it in the box provided and hit enter.\n",
    "\n",
    "You can nevigate the file system by clicking the \"Files\" tab in the  <-- left side bar. All your google drive files should be in `/content/drive/My\\ Drive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "fYyYzWxHlkSl",
    "outputId": "577796f4-433f-4aa2-df3c-0ec9bba8298d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_JW4rDYwScT"
   },
   "outputs": [],
   "source": [
    "# MAKE SURE THESE MATCH THE PATH OF THE IMPORTED TUB\n",
    "from pathlib import Path\n",
    "_data_root=Path('/content/data/tub/')\n",
    "\n",
    "_tf_record_dir = Path('/content/data/tf-records')\n",
    "_tf_record_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# This is the root directory for your TFX pip package installation.\n",
    "# _tfx_root = tfx.__path__[0]\n",
    "\n",
    "# # This is the path where your model will be pushed for serving.\n",
    "# _serving_model_dir = os.path.join(\n",
    "#     tempfile.mkdtemp(), 'serving_model/dingo')\n",
    "\n",
    "# # Set up logging.\n",
    "# absl.logging.set_verbosity(absl.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTZR5tbJvMBd"
   },
   "source": [
    "## Import some required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5cY4k5lb4d9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rab1zh1ovbre"
   },
   "source": [
    "## Load and visualise the data\n",
    "\n",
    "The Dingocar model takes a single image, passes it through a CNN and attempts to output both steering and throttle commands. The data is in the following form.\n",
    "\n",
    "```\n",
    "data_dir/\n",
    "  record_xxx.json\n",
    "  ...\n",
    "  xxx_cam-image_array_.jpg\n",
    "  ...\n",
    "```\n",
    "\n",
    "Where `xxx` corrispond to image/label pairs, ie `record_0.json` is the label for the image `0_cam-image_array_.jpg`.\n",
    "\n",
    "The contents of `record_xxx.json` looks like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"timestamp\": \"2019-04-03 07:39:09.646350\",\n",
    "  \"cam/image_array\": \"0_cam-image_array_.jpg\",\n",
    "  \"user/mode\": \"user\",\n",
    "  \"user/throttle\": 0,\n",
    "  \"user/angle\": 0\n",
    "}\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "  - `timestamp`: is the time at which the frame was captured\n",
    "  - `cam/image_array`: the name of the corrisonding image\n",
    "  - `user/mode`: who was driving the car at the time of data acquisition\n",
    "  - `user/throttle`: float 0-1 corrisponding to throttle command at the time the frame was captured\n",
    "  - `user/angle`: float 0-1 corrisponding to steering command at the time the frame was captured.\n",
    "\n",
    "We're only really interested in `user/angle` and `user/throttle` and the image data for this work.\n",
    "\n",
    "Here we are simply loading and displaying a single image/label pair to check that things have been downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "C5bGnHCAbpwP",
    "outputId": "c4279e71-144c-4d9f-d9d7-c0a378698e6f"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "label_paths = list(_data_root.glob(\"record_*.json\"))\n",
    "\n",
    "IMAGE_KEY    = \"cam/image_array\"\n",
    "STEERING_KEY = \"user/angle\"\n",
    "THROTTLE_KEY = \"user/throttle\"\n",
    "\n",
    "def read_image(path):\n",
    "  img = Image.open(path)\n",
    "  img = np.array(img, dtype=np.uint8)\n",
    "  return img\n",
    "\n",
    "def read_label(path):\n",
    "  with path.open('r') as f:\n",
    "    label = json.load(f)\n",
    "  return label\n",
    "\n",
    "# Read a single label\n",
    "idx = 123\n",
    "label = read_label(label_paths[idx])\n",
    "image_name = label[IMAGE_KEY]\n",
    "image_path = str(_data_root / image_name)\n",
    "image = read_image(image_path)\n",
    "\n",
    "print(f\"Steering: {label[STEERING_KEY]}\")\n",
    "print(f\"Throttle: {label[THROTTLE_KEY]}\")\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "caw3JnM_4jxj"
   },
   "source": [
    "# Convert to TFRecord\n",
    "\n",
    "The first step in the TFX pipeline is `ExampleGen` this expects our data to be in a specific format `TFRecord`. This is a serialized data format that can be a bit cumbersome to deal with for a small project like this, but it serves two main pourposes.\n",
    "\n",
    "1. When training models (expecially smaller ones like this) sometimes the a major bottleneck is not the model backprop step, it is simply loading data into the gpu. To run a maximum efficency you want your gpu to be maxed out a much as possiable. Serialized data facilitates this.\n",
    "\n",
    "2. When training across multiple machines in the cloud, data transfer from storage to the training machine becomes a segnificant bottleneck. Serialized data can be moved between infrastructure faster.\n",
    "\n",
    "`TFRecords` are composed of `TFExamples`. Each `TFExample` is a image/lable pair\n",
    "with some additional information to help with decoding the data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wg0iaPEz4rbl"
   },
   "outputs": [],
   "source": [
    "# Where to save the resulting TFRecord\n",
    "tfrecords_filename = str(_tf_record_dir / \"tf_record.record\")\n",
    "\n",
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def read_image_as_byte_string(path):\n",
    "  # \"image/raw\" has bytes value \"None\" which cannot be decoded as a UTF-8 string.\n",
    "  image_string = open(str(path), 'rb').read()\n",
    "  return image_string\n",
    "\n",
    "\n",
    "def image_example(record_path, data_dir):\n",
    "  \"\"\"Loads an image/label pair and converts to a tf.Example\n",
    "\n",
    "  Args:\n",
    "    record_path (str): Path to a record.json\n",
    "    data_dir (str): Path to the directory where records and images are stored\n",
    "\n",
    "  Returns:\n",
    "    tf.Example\n",
    "  \"\"\"\n",
    "  label = read_label(record_path)\n",
    "  steering = label[STEERING_KEY]\n",
    "  throttle = label[THROTTLE_KEY]\n",
    "  image_name = label[IMAGE_KEY]\n",
    "  image_path = _data_root / image_name\n",
    "  image_string = read_image_as_byte_string(image_path)\n",
    "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "\n",
    "  feature = {\n",
    "      'image/height': _int64_feature(image_shape[0]),\n",
    "      'image/width': _int64_feature(image_shape[1]),\n",
    "      'image/depth': _int64_feature(image_shape[2]),\n",
    "      'label/steering': _float_feature(steering),\n",
    "      'label/throttle': _float_feature(throttle),\n",
    "      'image/raw': _bytes_feature(image_string),\n",
    "  }\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecords_filename) as writer:\n",
    "  for path in label_paths:\n",
    "    example = image_example(path, _data_root)\n",
    "    writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4PzfXPMNVwg"
   },
   "source": [
    "# Read TFRecord\n",
    "\n",
    "This step is not crucial, we're just reading in a the `TFRecord` and decoding a `TFExample` to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "1VrUylqYNZey",
    "outputId": "3eca13c4-27f0-4f5f-a511-600e6446c863"
   },
   "outputs": [],
   "source": [
    "def decode_tfexample(example):\n",
    "  \"\"\"Decode a single tf.Example\n",
    "\n",
    "  Args:\n",
    "    example (tf.Example): A single tf.Example \n",
    "\n",
    "  Returns:\n",
    "    image/label pair (np.array, (float, float)): (image array, (steering, throttle))\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  height = (example.features.feature['image/height']\n",
    "                                .int64_list\n",
    "                                .value)[0]\n",
    "  \n",
    "  width = (example.features.feature['image/width']\n",
    "                              .int64_list\n",
    "                              .value)[0]\n",
    "\n",
    "  img_string = (example.features.feature['image/raw']\n",
    "                                .bytes_list\n",
    "                                .value)[0]\n",
    "  \n",
    "  steering = (example.features.feature['label/steering']\n",
    "                            .float_list\n",
    "                            .value)[0]\n",
    "\n",
    "  throttle = (example.features.feature['label/throttle']\n",
    "                        .float_list\n",
    "                        .value)[0]\n",
    "\n",
    "  img_flat = tf.image.decode_jpeg(img_string).numpy()\n",
    "  image_arr = img_flat.reshape((120, 160, -1))\n",
    "\n",
    "  return image_arr, (steering, throttle)\n",
    "\n",
    "filenames = [tfrecords_filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "for raw_record in raw_dataset.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  (image_arr, (steering, throttle)) = decode_tfexample(example)\n",
    "print(f'label: {steering}')\n",
    "print(f'throttle: {throttle}')\n",
    "imshow(image_arr)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFIFN6HPSsYk"
   },
   "outputs": [],
   "source": [
    "# Here, we create an InteractiveContext using default parameters. This will\n",
    "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
    "# To use your own pipeline root or database, the optional properties\n",
    "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
    "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
    "# notebook.\n",
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7US-2tB7ksXv"
   },
   "source": [
    "# Example Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZDtB9n-dm6n"
   },
   "outputs": [],
   "source": [
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.components.example_gen.import_example_gen.component import ImportExampleGen\n",
    "from  tfx.proto import example_gen_pb2\n",
    "\n",
    "examples = external_input(_tf_record_dir)\n",
    "# https://www.tensorflow.org/tfx/guide/examplegen#custom_inputoutput_split\n",
    "# has a good explanation of splitting the data the 'output_config' param\n",
    "\n",
    "# Input train split is _tf_record_dir/*'\n",
    "# Output 2 splits: train:eval=8:2.\n",
    "\n",
    "train_ratio = 8\n",
    "eval_ratio  = 10-train_ratio\n",
    "output = example_gen_pb2.Output(\n",
    "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                 example_gen_pb2.SplitConfig.Split(name='train',\n",
    "                                                   hash_buckets=train_ratio),\n",
    "                 example_gen_pb2.SplitConfig.Split(name='eval',\n",
    "                                                   hash_buckets=eval_ratio)\n",
    "             ]))\n",
    "example_gen = ImportExampleGen(input=examples,\n",
    "                               output_config=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "colab_type": "code",
    "id": "PXea8BoLeotw",
    "outputId": "8226a688-1860-4c96-93ba-2a431cf253ed"
   },
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7Ub6tNGksX5"
   },
   "source": [
    "# Decode Example From Example Gen. Just to see if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nrajWtFJgmgY",
    "outputId": "49dedce6-0d17-458f-ffda-e37d35077279"
   },
   "outputs": [],
   "source": [
    "artifact = example_gen.outputs['examples'].get()[0]\n",
    "print(artifact.split_names, artifact.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nlfJhDp_g07g",
    "outputId": "f1a54115-7aa5-433d-aa31-b47f57026dd7"
   },
   "outputs": [],
   "source": [
    "# Get the URI of the output artifact representing the training examples, which is a directory\n",
    "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'train')\n",
    "\n",
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "# Iterate over the first 1 records and decode them.\n",
    "for tfrecord in dataset.take(1):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)\n",
    "\n",
    "(image_arr, (steering, throttle)) = decode_tfexample(example)\n",
    "print(f'label: {steering}')\n",
    "print(f'throttle: {throttle}')\n",
    "imshow(image_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fh6hMqRksYE"
   },
   "source": [
    "# Stastics Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl_WAPtxRgWZ"
   },
   "outputs": [],
   "source": [
    "  # stats_options = StatsOptions(\n",
    "  #     enable_semantic_domain_stats = True)\n",
    "\n",
    "# Squashing logging so StatisticsGen doesn't complain\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "statistics_gen = StatisticsGen(\n",
    "  examples=example_gen.outputs['examples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dQps3v9ksYH"
   },
   "source": [
    "###   ☹ ☹ ☹ ☹ WARNINGS OCCUR HERE ☹ ☹ ☹ ☹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "N-oUEy5ZhO1S",
    "outputId": "e18cd2dc-5182-4726-e64b-204b21d838ff"
   },
   "outputs": [],
   "source": [
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S07tyNilu4zB",
    "outputId": "2c84b032-a774-4ce7-e031-5e1f02de3477"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "EbHhbtKY2HLM",
    "outputId": "aaadfe76-b54a-413c-bf45-ba4857baecfe"
   },
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=True)\n",
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "6eKojPJYxwCj",
    "outputId": "8811ab44-edb2-4ddf-e5cd-854a759f2747"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "vZ-FjDjtxz2N",
    "outputId": "1cff397d-92fb-4bec-90c6-225a63ce97d0"
   },
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "yH6U98x8xz70",
    "outputId": "6b30bfa6-2f28-48c4-b819-b30eb13875be"
   },
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9z8KXQ5xz_o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzeKLufBxz5h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6yxajE8xzz3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfJKQ8P2yP0R"
   },
   "source": [
    "# Old Donkey car code below. I think  I need this for the Transfrom step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTgPgXrvwfZO"
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation allows us to add a bit more variety to the training data. One very handy augmentation transformation is to randomly mirror the input image and the steering label. This ensurse the data contains the same number or left and right turns so the neural network does not become bias to a specifc direction of turn. \n",
    "\n",
    "There are also some other augmentation transformations you can apply below. These will hopefully make the network a bit more robust to canging lighting and help prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgyHZlg52GFl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NKOHhsgiawL"
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from functools import partial\n",
    "from dingocar.parts.augmentation import apply_aug_config\n",
    "\n",
    "# Play with the data augmentation settings if you like\n",
    "# In all cases 'aug_prob' is the probability the given \n",
    "# augmentation will occure. All the other parameters are\n",
    "# explained below.\n",
    "aug_config = {\n",
    "\n",
    "# Mirror the image horizontally\n",
    "\"mirror_y\"         : {\"aug_prob\" : 0.5},\n",
    "\n",
    "# Randomly turn pixels black of white.\n",
    "# \"noise\" : The probability a pixel is affected.\n",
    "#           0.0 : No pixels will be effected\n",
    "#           1.0 : All pixels will be effected\n",
    "                 \"salt_and_pepper\"  : {\"aug_prob\" : 0.3,\n",
    "                                       \"noise\"    : 0.2},\n",
    "\n",
    "# Randomly turn pixels a random color\n",
    "# \"noise\" : The probability a pixel is affected.\n",
    "#           0.0 : No pixels will be effected\n",
    "#           1.0 : All pixels will be effected\n",
    "                 \"100s_and_1000s\"   : {\"aug_prob\" : 0.3,\n",
    "                                       \"noise\"    : 0.2},\n",
    "\n",
    "# Randomly increase or decrease the pixel values by an \n",
    "# value between 'min_val' and 'max_val'. The resulting\n",
    "# value will be clipped between 0 and 255    \n",
    "                 \"pixel_saturation\" : {\"aug_prob\" : 0.3,\n",
    "                                       \"min_val\"  :-20,\n",
    "                                       \"max_val\"  : 20},\n",
    "\n",
    "# Randomly shuffle the RGB channel order\n",
    "                 \"shuffle_channels\" : {\"aug_prob\" : 0.3},\n",
    "\n",
    "# Randomly set a rectangular setction of the image to 0\n",
    "# the rectangle height and width is randomly generated \n",
    "# to be between dimention*min_frac and dimention*max_frac.\n",
    "# So min_frac = 0.0 and max_frac = 1.0 would result\n",
    "# in a random rectangel that could cover the entire image, \n",
    "# or none of the image or anywhere inbetween.\n",
    "                 \"blockout\"         : {\"aug_prob\" : 0.3,\n",
    "                                       \"min_frac\" : 0.07,\n",
    "                                       \"max_frac\" : 0.3}\n",
    "                }\n",
    "\n",
    "# If you're unfamiliar with the 'partial' function. It allows you to\n",
    "# call a function with some of the arguments pre-filled.\n",
    "# In this case we made a function that is like 'apply_aug_config', but\n",
    "# has the `aug_config` parameter pre-filled.\n",
    "record_transform=partial(apply_aug_config, aug_config=aug_config)\n",
    "\n",
    "record = tub.get_record(idx, record_transform=record_transform)\n",
    "print(f\"Steering: {record[STEERING_KEY]}\")\n",
    "print(f\"Throttle: {record[THROTTLE_KEY]}\")\n",
    "imshow(record[IMAGE_KEY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXTPjEyw42Ll"
   },
   "source": [
    "## Define the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySzdjLrjvqBZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Convolution2D\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from dingocar.parts.keras import KerasLinear\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "\n",
    "# Tub objects maintain a dictionary of data. You can access the data via 'keys'.\n",
    "# Traditionally x stands for inputs and y stands for outputs.\n",
    "# In our case, for every input image (x) there are 2 output labels,\n",
    "# steering angle and throttle (y).\n",
    "X_KEYS = [IMAGE_KEY]\n",
    "Y_KEYS = [STEERING_KEY, THROTTLE_KEY]\n",
    "\n",
    "# If you'd like you can play with this neural network as much as you like. See\n",
    "# if you can get the network to be more accurate!\n",
    "# The only things you need to watch out for are:\n",
    "#   1. 'img_in' cannot change.\n",
    "#   2. 'angle_out' must always haev 'units=1'\n",
    "#   3. 'throttle_out' must always have 'units=1'\n",
    "def convolutional_neural_network():\n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')                                                                                                                       \n",
    "    x = img_in                                                                                                                                                               \n",
    "    \n",
    "    # Convolution2D class name is an alias for Conv2D \n",
    "    x = Convolution2D(filters=24, kernel_size=(5, 5), strides=(2, 2), activation='relu')(x)                                                                                  \n",
    "    x = Convolution2D(filters=32, kernel_size=(5, 5), strides=(2, 2), activation='relu')(x)                                                                                  \n",
    "    x = Convolution2D(filters=64, kernel_size=(5, 5), strides=(2, 2), activation='relu')(x)                                                                                  \n",
    "    x = Convolution2D(filters=64, kernel_size=(3, 3), strides=(2, 2), activation='relu')(x)                                                                                  \n",
    "    x = Convolution2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu')(x)                                                                                  \n",
    "    \n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(units=100, activation='linear')(x)                                                                                                                             \n",
    "    x = Dropout(rate=.2)(x)\n",
    "    x = Dense(units=50, activation='linear')(x)                                                                                                                              \n",
    "    x = Dropout(rate=.2)(x)\n",
    "    # categorical output of the angle\n",
    "    angle_out = Dense(units=1, activation='linear', name='angle_out')(x)                                                                                                     \n",
    "    \n",
    "    # continous output of throttle\n",
    "    throttle_out = Dense(units=1, activation='linear', name='throttle_out')(x)                                                                                               \n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])                                                                                                        \n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'mean_squared_error',\n",
    "                        'throttle_out': 'mean_squared_error'},\n",
    "                  loss_weights={'angle_out': 0.5, 'throttle_out': 0.5})                                                                                                       \n",
    "    \n",
    "    return model\n",
    "\n",
    "# KerasLinear is a class the contains some functions we can use to train\n",
    "# our model and to get predictions out if it later.\n",
    "model = KerasLinear(model=convolutional_neural_network())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlRSHuy4yRaq"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfWs2ZsAbpwV"
   },
   "outputs": [],
   "source": [
    "from manage import train\n",
    "import config\n",
    "\n",
    "# Load 16 image at a time into the model\n",
    "BATCH_SIZE       = 32\n",
    "\n",
    "# 70% of the data is used for training. 30% for validation\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "\n",
    "# Number of time to look over all the training data\n",
    "EPOCHS = 100\n",
    "\n",
    "# Stop training if the validation loss has not improved for the last 'PATIENTS'\n",
    "# Epochs.\n",
    "USE_EARLY_STOP = True \n",
    "PATIENCE = 5\n",
    "\n",
    "\n",
    "# Where to save the trained model\n",
    "new_model_path = \"/content/drive/My Drive/dingocar/no_mirror1.hdf5\"\n",
    "\n",
    "# If you want to start from a pre-trained model you can add the path here\n",
    "base_model_path   = None\n",
    "\n",
    "\n",
    "# These are generators that will be used to feed data into the model\n",
    "# when training. The generator uses a constant random seed so the train/val\n",
    "# split is the same every time.\n",
    "train_gen, val_gen = tub.get_train_val_gen(X_KEYS, Y_KEYS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      train_frac=TRAIN_TEST_SPLIT,\n",
    "                      train_record_transform=record_transform,\n",
    "                      val_record_transform=None)\n",
    "\n",
    "training_history = model.train(train_gen,\n",
    "                               val_gen,\n",
    "                               new_model_path,\n",
    "                               epochs=EPOCHS,\n",
    "                               patience=PATIENCE,\n",
    "                               use_early_stop=USE_EARLY_STOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BltoY8j73oi8"
   },
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htFvxNxUh7ta"
   },
   "outputs": [],
   "source": [
    "from dingocar.parts.keras import KerasLinear\n",
    "\n",
    "new_model_path = \"/content/drive/My Drive/dingocar/no_mirror1.hdf5\"\n",
    "trained_model = new_model_path\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = KerasLinear()\n",
    "model.load(trained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXGqx9qir4Mz"
   },
   "outputs": [],
   "source": [
    "from dingocar.parts.datastore import Tub\n",
    "\n",
    "_, val_gen = tub.get_train_val_gen(X_KEYS, Y_KEYS,\n",
    "                      batch_size=1,\n",
    "                      train_frac=TRAIN_TEST_SPLIT,\n",
    "                      train_record_transform=None,\n",
    "                      val_record_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VLJwLnw4Fae"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "truth = []\n",
    "\n",
    "val_count = int(tub.get_num_records() * (1-TRAIN_TEST_SPLIT))\n",
    "for _ in tqdm(range(val_count)):\n",
    "    sample = next(val_gen)\n",
    "    pred = model.run(sample[0][0][0])\n",
    "    preds.append(pred)\n",
    "    truth.append((sample[1][0][0], sample[1][1][0]))\n",
    "        \n",
    "preds = np.array(preds)\n",
    "truth = np.array(truth)\n",
    "print(preds.shape)\n",
    "print(truth.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqOdY7MZ4GOR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean_squared_error(preds, true):\n",
    "  squared_error = (true - preds)**2\n",
    "  return np.mean(squared_error)\n",
    "\n",
    "def xy_scatter(preds, truth):\n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "    steering_p = preds[...,0]\n",
    "    throttle_p = preds[...,1]\n",
    "    steering_t = truth[...,0]\n",
    "    throttle_t = truth[...,1]\n",
    "    \n",
    "    steering_mse = mean_squared_error(steering_p, steering_t)\n",
    "    throttle_mse = mean_squared_error(throttle_p, throttle_t)\n",
    "    plt.plot(steering_p, steering_t, 'b.')\n",
    "    plt.title(f\"MSE: {steering_mse:.3f}\")\n",
    "    plt.xlabel(\"predictions\")\n",
    "    plt.ylabel(\"ground truth\")\n",
    "    plt.gca().set_xlim(-1, 1)\n",
    "    plt.show()\n",
    "#     fig = plt.gcf()\n",
    "#     fig.savefig(path + \"/pred_vs_anno.png\", dpi=100)\n",
    "\n",
    "# Only display the validation set\n",
    "xy_scatter(preds, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_fWaIAD4Y-S"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "truth = []\n",
    "\n",
    "for idx in tqdm(range(tub.get_num_records())):\n",
    "    sample = tub.get_record(idx)\n",
    "    pred = model.run(sample[IMAGE_KEY])\n",
    "    preds.append(pred)\n",
    "    truth.append((sample[STEERING_KEY], sample[THROTTLE_KEY]))\n",
    "        \n",
    "preds = np.array(preds)\n",
    "truth = np.array(truth)\n",
    "print(preds.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjnOvTvcEYcW"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wt6QEr6_D9Qd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plt_image(ax, image, title):\n",
    "  ax.imshow(image)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  ax.set_title(title)\n",
    "\n",
    "def plt_samples(idxs, axs, tub):\n",
    "  records = [tub.get_record(i) for i in idxs]\n",
    "  images = [r[IMAGE_KEY] for r in records]\n",
    "  titles = [f\"frame: {i}\" for i in idxs]\n",
    "  for a,i,t in zip(axs, images, titles):\n",
    "    plt_image(a,i,t)\n",
    "        \n",
    "def time_series(x=300):#, axs=axs, tub=tub):\n",
    "  \n",
    "    fig = plt.figure(figsize=(21,12))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax1 = plt.subplot2grid((2, 5), (0, 0), colspan=5)\n",
    "    ax2 = plt.subplot2grid((2, 5), (1, 0))\n",
    "    ax3 = plt.subplot2grid((2, 5), (1, 1))\n",
    "    ax4 = plt.subplot2grid((2, 5), (1, 2))\n",
    "    ax5 = plt.subplot2grid((2, 5), (1, 3))\n",
    "    ax6 = plt.subplot2grid((2, 5), (1, 4))\n",
    "    axs = [ax2, ax3, ax4, ax5, ax6]\n",
    "    steering_p = preds[...,0]\n",
    "    throttle_p = preds[...,1]\n",
    "    steering_t = truth[...,0]\n",
    "    throttle_t = truth[...,1]\n",
    "  \n",
    "    idxs = np.arange(x-2,x+3)\n",
    "    plt_samples(idxs, axs, tub)\n",
    "  \n",
    "    start = x-300\n",
    "    end  = x + 300\n",
    "    ax1.plot(steering_p, label=\"predictions\")\n",
    "    ax1.plot(steering_t, label=\"ground truth\")\n",
    "    #ax1.axvline(x=x, linewidth=4, color='r')\n",
    "    ax1.legend(bbox_to_anchor=(0.91, 0.96), loc=2, borderaxespad=0.)\n",
    "    ax1.set_title(\"Time Series Throttle Predictions vs Ground Truth\")\n",
    "    ax1.set_xlabel(\"time (frames)\")\n",
    "    ax1.set_ylabel(\"steering command\")\n",
    "    ax1.set_xlim(start, end)\n",
    "    \n",
    "#time_series(x=600)\n",
    "interact(time_series, x=(300, len(truth-300)))#, axs=fixed(axs), tub=fixed(tub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oM1OQMMDStqQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    \n",
    "testData = np.array([[0,0], [0.1, 0], [0, 0.3], [-0.4, 0], [0, -0.5]])\n",
    "fig, ax = plt.subplots()\n",
    "sctPlot, = ax.plot(testData[:,0], testData[:,1], \"o\", picker = 5)\n",
    "plt.grid(True)\n",
    "plt.axis([-0.5, 0.5, -0.5, 0.5])\n",
    "\n",
    "def on_pick(event):\n",
    "    artist = event.artist\n",
    "    artist.set_color(np.random.random(3))\n",
    "    print(\"click!\")\n",
    "    fig.canvas.draw()\n",
    "\n",
    "fig.canvas.mpl_connect('pick_event', on_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZgvXFLBSyhl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TFX dingocar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
